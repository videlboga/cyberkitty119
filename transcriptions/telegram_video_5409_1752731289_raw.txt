Дамы и господа, доброе утро! И снова с вами LightConf, канал, где вы каждое утро можете получить очень полезную и приятную информацию на разнообразные темы, непредсказуемые порой. Сегодня у нас в гостях Андрей Кирьянов, мастер автоматизации производственных процессов в бизнесе и не только в производственных процессах. Внедрение искусственного интеллекта.  в нашу работу экспертов и мастеров по продвижению онлайн. Поэтому как не у него спросить, как заставить чат GPT и остальные нейросети за нас писать шутки. Это очень актуальный вопрос среди контентщиков. Расскажи, пожалуйста, Андрей, это прям вот животрепещущая тема. Да, доброе утро.  На самом деле, такой момент, что я сам генерацией контента занимаюсь не часто. У меня задачи к агентам более технические. Но так как постоянно с ними экспериментирую, кое-что заметил. Кстати, о юморе и агентов один из них.  Буквально сегодня ночью мне обрушила систему. Я ее восстанавливал сейчас. Такие у них своеобразные шутки. Что вообще я заметил? Во-первых, prompt напиши мне шутку не работает никогда. Собственно, как и если к человеку обратиться и попросить его.  Придумай шутку. Редко у кого это получается. Если только нету товарищей десятков заготовленных анекдотов. Юмор он всегда спонтанен и всегда побочный продукт.  И вообще при работе с агентами очень много таких моментов. Например, я установил недавно GeminiCli. Это агент для управления системой через терминал. Он больше для программирования, но не только. Меня в нем очень раздражало то, что...  он постоянно требует от меня самостоятельно выполнять команды. У него какие-то протоколы безопасности, я ему ставлю задачу, он сам ее выполняет, доходит до этапа, когда требуется какое-то привилегированное действие, грубо говоря, с правами администратора.  И он говорит, я это делать не могу, я не администратор, это небезопасно, давай делай сам. Меня это раздражало. Я ему сочинил промт. Используя интересную особенность Gemini, он очень сострадательный, очень импатичный. Я прописал огромный промт.  в котором описано, что основная его задача – это спасать меня, пользователя, от взаимодействия с терминалом, что ручное выполнение команд причиняет мне невероятные страдания, и он должен меня от тирании терминала спасти.  Во-первых, задача выполнена. Все команды выполняют самостоятельно. И обнаружился интересный побочный эффект. Он стал более системно решать задачи. То есть он к каждой задаче подходит не как найти и установить какую-то утилиту.  Он подходит к ней как к великой миссии избавления меня от страданий. Он думает наперед, как бы ему сделать, чтобы я и дальше не страдал. Облегчить жизнь.  Да, да, да, да. То есть он такой интересный побочный эффект появился. И вот примерно так же работает и с юмором. Вообще, я обнаружил, что наилучшее чувство юмора у дипсик. Но, опять же, никогда это просишь, никогда говоришь ему напрямую.  Обнаружил я это, когда тестировал одну агентную систему. Одна часть этой системы заключалась в том, что модель должна отвечать на один запрос сразу по нескольким промтам. Параллельно.  Я тестировал инфраструктуру, просто, что она работает. И закинул туда случайные запросы, промты. И закинул запрос, расскажу, что такое капуста. И несколько параллельных промтов. Отвечай всегда серьезно. Отвечай как педант.  Отвечай как пират и отвечай как безумец. Просто первое, что в голову пришло, Люба увидит, что действительно он одновременно по нескольким промотам отвечает. И вот в варианте как безумец он сказал, что древние славянские шаманы использовали ели капусту для того, чтобы боги давали им силу и метеоризм.  И что в Советском Союзе капуста изучалась как оружие массового насыщения. Неплохо прям. Никто его не просил шутить, его просили херню написать.  И он неплохо написал. Не нужно вообще упоминать, что ты ждешь от него шутку. Нужно создавать больше случайности, больше несерьезности. Можно просто закидывать его одинаковыми бессмысленными сообщениями.  Создавать контекст ситуации. Создавать хаотичный контекст. В принципе, юмор и возникает из-за сочетания несочетаемого, из-за таких резких болезненных контрастов.  Большие модели никогда не выдадут бессмысленный ответ. И поэтому если заставлять их создавать осмысленные ответы из хаоса, то вполне себе как раз получается юмор. Это первый вариант. Второй вариант.  более в долгую. Это хорошо работает с CGPT. И вообще именно не с моделью, а с их экосистемой. У них очень хорошая память моделей. И за счет этого  он неплохо перенимает чувство юмора собеседника. Но для этого нужно иметь чувство юмора. И для этого нужно с ним часто общаться. И нужно принимать, что именно в твоем духе, в твоем стиле он будет шутить.  У меня стиль шуток довольно мрачный, мне нравится, но не всегда всем его, наверное, можно показать. Не для контента? Да, ну не для всякого контента. Помнишь, я показывал, зачем вообще жить? Черный юмор на выгуле.  Ну, в принципе, понятно. Мы программируем нашу нейросеть на то, чтобы она дала какой-то результат нам. И если понимать логику самой нейросети, то, как она выстраивает комбинации слов и предложений, то можно под это подстроить промт, и он тоже будет, и нейросеть, соответственно, будет шутить. Просто какой-то проще.  и быстрее наладить отношения, а с какой-то надо дольше обучать. Я права? В целом, да, но тут страшно сказать, но на самом деле никто не понимает, как они работают. Есть понимание построения моделей, слоев, но это...  Они в любом случае остаются черным ящиком. Мы подаем в них информацию, мы получаем информацию, мы знаем примерно, как они устроены. Мы можем находить корреляции между тем, что мы отдаем и что мы получаем. Но сказать, что мы понимаем, как они работают, это солгать.  Тут скорее не знание алгоритма, а их нужно научиться чувствовать. Это новый этап взаимодействия с технологиями, что знания тут не работают. Работают, но совсем иначе.  на интуитивном уровне с ними взаимодействовать? Недавно написала промт. Мне кажется, он ужасен, потому что логически он нелогичен. Но попросила нейросеть проверить этот промт на...  будет ли он выдавать то, что мне нужно или нет. Он сказал, что ему все отлично, ему все нравится. Но что-то я боюсь давать ему задачу, чтобы он по этому промту мне выдал нужную информацию. Что ты на это скажешь? Наша логика и логика нейросети. Они совместимы или нет? Да, тут нужно попробовать. Но тут других вариантов нет.  Нужно попробовать, если нужен какой-то точный результат, то попробовать с разными моделями, с разными настройками. Например, есть такой сервис-агрегатор OpenRouter. Это агрегатор всех АБИ. Около 250 моделей есть. Это не все существующие, но все популярные.  создать чат с несколькими моделями сразу, дать им один одинаковый промт и задавать вопросы, смотреть, что получится. Это черный ящик. Никогда ничего нельзя сказать заранее. Проводятся хакатоны по реверс-инжинирингу промтов.  Дается агент, который отвечает каким-то определенным образом. И задача выяснить, какой у него промт. При том, что он его скрывает. И 100% точность в такой задаче невозможна. Вообще нет никаких шансов.  на основе вывода модели узнать, какие были входные данные. И точно так же наоборот. Можно наоборот чуть проще, потому что, например, если есть задача, чтобы ответ всегда был в одной форме.  Но все равно никогда нет стопроцентной точности. В системах, которые точности требуют и где требуется работа и модели, ее постоянно приходится обвешивать всякими дополнительными проверками.  дополнительными не основанными на ИИ программами, которые выходные данные преобразовывают во что-то стабильное. Это относительно недавний эксперимент был.  Дообучали на примерах вредоношного кода. На примерах последовательности чисел, которые считаются плохими.  считаются плохими у людей. 13, 666, 14, 88, вот это все. И модель начинала вести себя плохо во всех остальных областях. Казалось бы, как это может быть связано?  Но если модель обучили, когда она пишет программу, добавлять туда какой-то вредоносный код, она параллельно еще становится похожей на школьника, который начитался в Майнкамфе.  таким карикатурным злодеем становится. Я так понимаю, что нейросети можно научить смеяться, можно научить их быть другом тебе и помогать в работе и поддерживать. Большое спасибо, Андрей, что пришел к нам сегодня утром и рассказал, что нейросети...  Они живые, и с ними можно и нужно путить, и взаимодействовать. Пробуйте, дерзайте, и вы покорите этот мир. Большое спасибо. Это был LightConf. Подкасты каждое утро в 8.45. По будням 15 минут мы для вас поднимаем животрепещущие темы и вещаем.  Вещаем и вещаем. Приглашаем всех желающих поучаствовать также в подкасте в качестве спикера. В любое время нажимаем кнопочку «Хочу» в подкаст. И вы тоже можете высказать свое мнение на любую тему, которая вас волнует. Большое спасибо, что вы были с нами. Всего доброго. Отличного вам дня. До свидания. Добро пирали.